{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2 # 依据的单词数\n",
    "EMBEDDING_DIM = 10 # 词向量的维度\n",
    "# 我们使用莎士比亚的诗\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = [((test_sentence[i], test_sentence[i+1]), test_sentence[i+2])\n",
    "            for i in range(len(test_sentence)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('When', 'forty'), 'winters')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocb = set(test_sentence)\n",
    "word2idx = {word: i for i, word in enumerate(vocb)}\n",
    "idx2word = {word2idx[word]: word for word in word2idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Will': 0,\n",
       " 'This': 1,\n",
       " 'succession': 2,\n",
       " 'a': 3,\n",
       " 'livery': 4,\n",
       " 'say,': 5,\n",
       " 'being': 6,\n",
       " 'cold.': 7,\n",
       " \"feel'st\": 8,\n",
       " 'much': 9,\n",
       " 'When': 10,\n",
       " 'sum': 11,\n",
       " 'If': 12,\n",
       " 'old': 13,\n",
       " 'count,': 14,\n",
       " 'where': 15,\n",
       " 'thou': 16,\n",
       " 'to': 17,\n",
       " 'blood': 18,\n",
       " 'weed': 19,\n",
       " 'so': 20,\n",
       " 'lusty': 21,\n",
       " 'treasure': 22,\n",
       " 'brow,': 23,\n",
       " \"deserv'd\": 24,\n",
       " 'worth': 25,\n",
       " 'warm': 26,\n",
       " 'proud': 27,\n",
       " 'the': 28,\n",
       " 'made': 29,\n",
       " 'shall': 30,\n",
       " 'all': 31,\n",
       " 'mine': 32,\n",
       " 'Shall': 33,\n",
       " 'were': 34,\n",
       " 'see': 35,\n",
       " 'lies,': 36,\n",
       " 'couldst': 37,\n",
       " 'small': 38,\n",
       " 'Were': 39,\n",
       " 'on': 40,\n",
       " 'in': 41,\n",
       " 'an': 42,\n",
       " 'more': 43,\n",
       " 'use,': 44,\n",
       " 'praise': 45,\n",
       " 'Proving': 46,\n",
       " 'field,': 47,\n",
       " 'it': 48,\n",
       " 'Thy': 49,\n",
       " 'beauty': 50,\n",
       " 'And': 51,\n",
       " 'be': 52,\n",
       " 'old,': 53,\n",
       " 'and': 54,\n",
       " 'art': 55,\n",
       " 'Then': 56,\n",
       " 'by': 57,\n",
       " 'thine!': 58,\n",
       " 'days;': 59,\n",
       " 'gazed': 60,\n",
       " 'my': 61,\n",
       " 'winters': 62,\n",
       " \"totter'd\": 63,\n",
       " 'new': 64,\n",
       " 'To': 65,\n",
       " \"beauty's\": 66,\n",
       " 'dig': 67,\n",
       " 'held:': 68,\n",
       " 'now,': 69,\n",
       " 'forty': 70,\n",
       " 'sunken': 71,\n",
       " 'asked,': 72,\n",
       " 'within': 73,\n",
       " 'thy': 74,\n",
       " \"excuse,'\": 75,\n",
       " 'thriftless': 76,\n",
       " 'besiege': 77,\n",
       " 'eyes,': 78,\n",
       " 'deep': 79,\n",
       " 'answer': 80,\n",
       " 'shame,': 81,\n",
       " \"'This\": 82,\n",
       " 'child': 83,\n",
       " 'fair': 84,\n",
       " 'of': 85,\n",
       " 'all-eating': 86,\n",
       " 'when': 87,\n",
       " 'trenches': 88,\n",
       " 'make': 89,\n",
       " 'praise.': 90,\n",
       " 'How': 91,\n",
       " 'his': 92,\n",
       " \"youth's\": 93,\n",
       " 'Where': 94,\n",
       " 'own': 95,\n",
       " 'thine': 96}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class n_gram(nn.Module):\n",
    "    def __init__(self, vocb_size, context_size=CONTEXT_SIZE, n_dim=EMBEDDING_DIM):\n",
    "        super(n_gram, self).__init__()\n",
    "        self.embed = nn.Embedding(vocb_size, n_dim)\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(context_size * n_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, vocb_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        voc_embed = self.embed(x)\n",
    "        voc_embed = voc_embed.view(1, -1)\n",
    "        out = self.classify(voc_embed)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = n_gram(len(word2idx))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-2, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.058586\n",
      "Epoch: 40, Loss: 0.054333\n",
      "Epoch: 60, Loss: 0.051058\n",
      "Epoch: 80, Loss: 0.048464\n",
      "Epoch: 100, Loss: 0.046367\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    train_loss = 0\n",
    "    for word, label in trigram:\n",
    "        word = Variable(torch.LongTensor([word2idx[i] for i in word]))\n",
    "        label = Variable(torch.LongTensor([word2idx[label]]))\n",
    "        # forward\n",
    "        out = net(word)\n",
    "        loss = criterion(out, label)\n",
    "        train_loss += loss.item()\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # display\n",
    "    if (e + 1) % 20 == 0:\n",
    "        print('Epoch: {}, Loss: {:.6f}'.format(e + 1, train_loss / len(trigram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ('so', 'gazed')\n",
      "label: on\n",
      "\n",
      "read word is on, predicted word is on\n"
     ]
    }
   ],
   "source": [
    "word, label = trigram[19]\n",
    "print('input: {}'.format(word))\n",
    "print('label: {}\\n'.format(label))\n",
    "word = Variable(torch.LongTensor([word2idx[i] for i in word]))\n",
    "out = net(word)\n",
    "pred_label_idx = out.max(1)[1].item()\n",
    "predicted_word = idx2word[pred_label_idx]\n",
    "print('read word is {}, predicted word is {}'.format(label, predicted_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (\"'This\", 'fair')\n",
      "label: child\n",
      "\n",
      "read word is child, predicted word is child\n"
     ]
    }
   ],
   "source": [
    "word, label = trigram[75]\n",
    "print('input: {}'.format(word))\n",
    "print('label: {}\\n'.format(label))\n",
    "word = Variable(torch.LongTensor([word2idx[i] for i in word]))\n",
    "out = net(word)\n",
    "pred_label_idx = out.max(1)[1].item()\n",
    "predicted_word = idx2word[pred_label_idx]\n",
    "print('read word is {}, predicted word is {}'.format(label, predicted_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
